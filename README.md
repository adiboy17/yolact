# yolact
YOLACT Google Colab Notebook
<ui5-button design="Emphasized">
https://colab.research.google.com/drive/1EB0tZ8N5ADiGkcFc3W-a2EA7g1mEUC3i
  
# -*- coding: utf-8 -*-
"""YOLACT-Eval.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ncRxvmNR-iTtQCscj2UFSGV8ZQX_LN0M

# YOLACT Google Colab Notebook
Inference on images and video with [YOLACT](https://github.com/dbolya/yolact).

## Google Colab
This notebook is set up to work inside Google Colab, which is a free, Linux-based Jupyter Notebook environment hosted in the cloud.

If you try it outside of Google Colab I'm not sure if it will work. I originally had problems running locally on my Windows machine, which is why I switched to this.

### Runtime Setup
- Go to Runtime > Change Runtime Type
- Choose GPU (TPU won't work)

## YOLACT
YOLACT is a state of the art, real-time, single shot object segmentation algorithm detailed in these papers:  
- [YOLACT: Real-time Instance Segmentation](https://arxiv.org/abs/1904.02689)
- [YOLACT++: Better Real-time Instance Segmentation](https://arxiv.org/abs/1912.06218)

**Big thanks to the authors: Daniel Bolya, Chong Zhou, Fanyi Xiao, Yong Jae Lee!**

## Immersive Limit
This notebook was created by Adam Kelly, instructor/creator of [immersivelimit.com](https://www.immersivelimit.com).
- Subscribe for lots more awesome AI and 3D content on the [YouTube channel](https://www.youtube.com/c/immersivelimit)
- Check out https://www.immersivelimit.com/connect for more ways to follow/connect ðŸ˜€
"""



"""# Initial Setup
First, we install some Python libraries. Google Colab probably has these requirements already, but better to include them than to break later.
"""

# Cython needs to be installed before pycocotools
!pip install cython
!pip install opencv-python pillow pycocotools matplotlib

# Downgrade torch to accommodate DCNv2
!pip install torchvision==0.5.0
!pip install torch==1.4.0

"""## Clone YOLACT from GitHub
Let's get that github repo! If anything in this notebook breaks, check the repo in case they've made updates.
"""

# Commented out IPython magic to ensure Python compatibility.
# Make sure we're in the top folder
# %cd /content

# Clone the repo
!git clone https://github.com/dbolya/yolact.git

"""## DCNv2
The DCNv2 external library is needed for this to work, so we'll build it now.

**IF YOU GET CUDA ERRORS** You need to change the Runtime of this notebook to "GPU" as mentioned at the top of the notebook.
"""

# Commented out IPython magic to ensure Python compatibility.
# Change to the right directory
# %cd /content/yolact/external/DCNv2

# Build DCNv2
!python setup.py build develop

"""## Pretrained Weights
In order to run inference, we'll need some pre-trained weights. The creator of the GitHub repo shared them on Google Drive. We're going to use a [helpful tool](https://github.com/adiboy17/download_google_drive) made by [Govind Singh](https://github.com/adiboy17) to easily access the Drive file from Colab.

If this stops working, it's probably because the weights moved to a different location. Check the YOLACT github repo to see where they went.
"""

# Commented out IPython magic to ensure Python compatibility.
# Make sure we're in the top folder
# %cd /content

# Clone the repo
!git clone https://github.com/adiboy17/download_google_drive.git

# Create a new directory for the pre-trained weights
!mkdir -p /content/yolact/weights

# Download the file
!python ./download_google_drive/download_gdrive.py 1ZPu1YR2UzGHQD0o1rEqy-j5bmEm3lbyP ./yolact/weights/yolact_plus_resnet50_54_800000.pth

"""# Get Test Images
We'll download a few test images from the [COCO dataset](http://cocodataset.org/#explore). Feel free to try out your own images as well, but know that there are only 80 categories and they're not intended to cover everything, so if you upload a picture of a snake, a mouse, and a cat, only the cat will be detected.
"""

# Commented out IPython magic to ensure Python compatibility.
# Make a new directory for the test images
!mkdir /content/test_images

# Move to the new directory
# %cd /content/test_images

# Make a list of URLs from the COCO dataset
get_imgs = ['https://img.gta5-mods.com/q75/images/los-santos-police-els-highway-patrol-charger/f091c4-File%2028-03-2017,%2020%2040%2056.jpeg',
            'http://www.tamsoldracecarsite.net/P21020627G.jpg',
            'https://www.reviewjournal.com/wp-content/uploads/2019/04/12015534_web1_webD3Vz5KpU4AEGcbp.jpg',
            'https://xwebforums.com/forum/index.php?attachments/ba8183e2-ca51-43f1-878c-5aa5ed224b6c-jpeg.19816/',
            'https://live.staticflickr.com/7606/16610964047_20df7ddf57_b.jpg']

# Download all the images
for img_url in get_imgs:
  !wget {img_url} -nc

# List the contents of the folder. Should have images.
!pwd
!ls

"""# Run Inference on Images
Let's run inference. We do that with eval.py
"""

# Commented out IPython magic to ensure Python compatibility.
# Move up to the top level directory
# %cd /content

# Delete any previous output_images folder (in case we're running this more than once)
!rm /content/output_images -r

# Create a new directory for output images
!mkdir -p /content/output_images

# Run inference using our pre-trained weights on all images in the directory
!python ./yolact/eval.py --trained_model=./yolact/weights/yolact_plus_resnet50_54_800000.pth --config=yolact_plus_resnet50_config --score_threshold=0.15 --top_k=15 --images=test_images:output_images

"""## Display Output Images
The last step saved output images, so we'll display those now.
"""

import cv2
import numpy as np
from matplotlib import pyplot as plt
from pathlib import Path

output_images = Path('output_images')

def show_image(img_path):
  img = cv2.imread(img_path)
  img_cvt=cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
  plt.figure(figsize=(16,16))
  plt.imshow(img_cvt)
  plt.show()

# Iterate through all of the output images and display them
for img_path in output_images.iterdir():
  print(img_path)
  show_image(str(img_path))

"""# Run Inference on Video
I can't figure out how to get Google Colab to show the output video in the notebook, so I've uploaded the video to YouTube. The mask quality is incredible. There are some false positives because it thinks the rocks are sheep, but we'll give it a pass because it's never been told what a rock is before (COCO dataset doesn't contain rocks) and the rocks do look a bit sheepish.
"""

from IPython.display import HTML
HTML('<iframe width="1280" height="720" src="https://www.youtube.com/embed/bQgtmbzN7jg" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>')

"""If you'd like to process your own video, you can modify the steps below."""

# Commented out IPython magic to ensure Python compatibility.
# Make a new directory for the test images
!mkdir -p /content/test_video

# Move to the top level directory
# %cd /content

# Download the file
# https://drive.google.com/file/d/1I4fivRLniVNt_LcWqhQNehTSdEkZ4ytW/view?usp=sharing
# Note that file_id is extracted from the share URL above, it'll be different for every file
file_id = "1I4fivRLniVNt_LcWqhQNehTSdEkZ4ytW"
file_path = "/content/test_video/giraffes_full_720.mp4" # <- this is the destination path

!python /content/download_google_drive/download_gdrive.py {file_id} {file_path}

!ls /content/test_video

"""Now we run inference."""

# Commented out IPython magic to ensure Python compatibility.
# %cd /content
!mkdir -p /content/output_videos
output_path = "/content/output_videos/giraffes_full_720_output.mp4"
!python ./yolact/eval.py --trained_model=./yolact/weights/yolact_plus_resnet50_54_800000.pth --score_threshold=0.15 --top_k=15 --video_multiframe=4 --video={file_path}:{output_path}

"""## Download the output file
In this part, we'll mount your Google Drive and you can copy the file somewhere over there. I tried using the google.colab.files library to download the file, but it doesn't seem to like big video files.

- You will need to authorize your Drive to connect, then it basically just links your drive as if it's a folder on this cloud computer.
- **Be careful** because if you start deleting/modifying files in this folder, you will modify your personal Google Drive.
"""

from google.colab import drive
drive.mount('/content/drive')

# Commented out IPython magic to ensure Python compatibility.
!mkdir -p /content/drive/My\ Drive/YOLACT_output
# %cd /content/drive/My\ Drive/YOLACT_output
!ls

!cp {output_path} /content/drive/My\ Drive/YOLACT_output/giraffes_full_720_output.mp4

"""## Find the Video on Google Drive
Now you should be able to view the file on your Google Drive in the YOLACT_output folder.

# Conclusion
ðŸŽ‰ Woohoo! You did it! ðŸŽ‰

Thanks for checking out the notebook, I hope it was helpful!

**If you liked it, consider sharing it!** YOLACT is pretty awesome, so more people should know about it.


### Want to learn how to Train on a custom dataset?

Check out this tutorial:

[Train YOLACT with a Custom COCO Dataset | Immersive Limit](https://www.immersivelimit.com/tutorials/train-yolact-with-a-custom-coco-dataset)
"""

##Images:
![1](https://github.com/adiboy17/yolact/blob/master/download%20(1).png
)
![2]https://github.com/adiboy17/yolact/blob/master/download%20(2).png)
![3](https://github.com/adiboy17/yolact/blob/master/download%20(3).png)
![4](https://github.com/adiboy17/yolact/blob/master/download%20(4).png)
![5](https://github.com/adiboy17/yolact/blob/master/download.png)
